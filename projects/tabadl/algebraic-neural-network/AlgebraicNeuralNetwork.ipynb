{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "This notebook explores the study of group symmetries and Lie algebras with a focus on training a neural network to optimize a loss function defined in terms of a mathematical expression that promotes producing a set of weights which satisfy certain commutator algebra. \n",
    "\n",
    "The architecture at the core of our model is Transformer-based, and the loss function is defined in terms of the higher-dimensional tensor output of the final fully-connected feed forward perceptron, non-linearity, and softmax operations, such that subject to certain constraints (which we will also attempt to learn during training) it is equivalent to some corresponding Lie Algebra. \n",
    "\n",
    "We will proceed with the following steps:\n",
    "1. Motivate and justify the problem with respect to group symmetries and Lie algebras.\n",
    "   A. We will accomplish this task via the following high-level process:\n",
    "      a. Define the problem we are trying to solve in terms of using gradient descent to train a neural network.\n",
    "      b. Define the axioms required to fully motivate and define the problem.\n",
    "      c. Introduce the notation we will use to describe and develop the axioms into a mathematical expression that constitutes a description of the problem, such that the axioms can be used to describe the problem via some graphical representations.\n",
    "      d. Define the loss function that we are trying to optimize in terms of the algebraic constraints we know must be satisfied.\n",
    "\n",
    "2. Develop and implement the neural network architecture and training logic, including the schema for the training data that we will need to build out before we can actually train it.\n",
    "\n",
    "3. Generate or compile the training data as described in step 2. This includes generating the holdout data which will be used to evaluate the model's performance post-training.\n",
    "\n",
    "4. Train the neural network per the logic described in step 2, using the training data generated in step 3.\n",
    "\n",
    "5. Test the neural network that results from step 4 using the logic described in step 2, which satisfies the conditions and constraints provided in step 1, using the held-out test data generated in step 3.\n",
    "\n",
    "\n",
    "# Step 1: \n",
    "## Motivate and justify the problem with respect to group symmetries and Lie algebras\n",
    "\n",
    "### Problem Statement\n",
    "\n",
    "We are trying to train a neural network to optimize its weights with respect to a loss function defined in terms of some associated Lie Algebra.  \n",
    "\n",
    "### Axioms\n",
    "\n",
    "The axioms that we will use to motivate and define the problem are:\n",
    "\n",
    "1. Group Symmetry\n",
    "\n",
    "2. Lie Algebra\n",
    "\n",
    "### Problem Definition\n",
    "\n",
    "We are trying to train a neural network to optimize its weights with respect to a loss function defined in terms of some associated Lie Algebra.\n",
    "\n",
    "## Group Symmetry\n",
    "\n",
    "Group symmetry is a fundamental axiom of group theory. It states that a group is symmetric if and only if it is associative and commutative.\n",
    "\n",
    "## Lie Algebra\n",
    "\n",
    "A Lie algebra is an algebraic structure that admits a Lie algebra algebraic structure."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Design, implement, and test the neural networks/liquid state machines.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 2.1 Definitions: Liquid Neural Networks/Liquid State Machines\n",
    "\n",
    "Liquid Neural Networks/Liquid State Machines (LNNs/LSMs) are a class of neural networks that are able to operate in a continuous state space.\n",
    "\n",
    "LNNs/LSMs can be used to simulate continuous-time systems.\n",
    "\n",
    "We can illustrate this using the underlying Linear Equations, but first we should introduce some notation...\n",
    "\n",
    "## 2.2 Notation\n",
    "\n",
    "### 2.2.1 Symbols\n",
    "\n",
    "We will use the following symbols:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\mathcal{X} &= \\mathbb{R}^n \\\\\n",
    "\n",
    "\\mathcal{U} &= \\mathbb{R}^m \\\\\n",
    "\n",
    "\\mathcal{Y} &= \\mathbb{R}^n \\\\\n",
    "\n",
    "\\mathcal{\\\n",
    "X} &= \\mathbb{R}^n \\\\\n",
    "\n",
    "\\mathcal{\\\n",
    "U} &= \\mathbb{R}^m \\\\\n",
    "\n",
    "\\mathcal{\\\n",
    "Y} &= \\mathbb{R}^n \\\\\n",
    "\\end{aligned}\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Principle of Least Action, and Noether's Theorem\n",
    "(Provide explanation here)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Tensor Calculus-based Derivation and Proof\n",
    "\n",
    "(Provide explanation and implementation here)\n",
    "\n",
    "## Implementing Noether's Theorem to define our Loss Function(s)\n",
    "\n",
    "(Provide explanation here)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
